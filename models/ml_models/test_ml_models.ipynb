{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "from datasets import *\n",
    "from models import *\n",
    "from trainer import *"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "claim_data = torch.Tensor(pd.read_pickle('../../data/claim_tensor.pkl'))\n",
    "county_data = torch.Tensor(pd.read_pickle('../../data/county_tensor.pkl'))\n",
    "hospitalizations_data = torch.Tensor(pd.read_pickle('../../data/hospitalizations.pkl'))\n",
    "distance_matrix = torch.Tensor(pd.read_pickle('../../data/distance_mat.pkl'))\n",
    "data_time = pd.read_pickle('../../data/date_range.pkl') #这个是list\n",
    "claim_data.shape, county_data.shape, hospitalizations_data.shape, distance_matrix.shape,"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "dynamic_data = torch.cat((claim_data,torch.unsqueeze(hospitalizations_data, -1)), -1)\n",
    "static_data = county_data\n",
    "label = torch.unsqueeze(hospitalizations_data, -1)\n",
    "dynamic_data = dynamic_data[:500]\n",
    "static_data = static_data[:500]\n",
    "label = label[:500]\n",
    "\n",
    "dynamic_data.shape, static_data.shape, label.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New load way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "preprocess = PreprocessData(dynamic_data = dynamic_data, static_data = static_data, label = label, input_window = 7, output_window = 3, type= 'temporal', mode = 0, method = 'mean')\n",
    "trainset, valset, testset = preprocess.getMlDataSetWithoutDivide()\n",
    "train_temporal_loader = get_dataloader(trainset)\n",
    "val_temporal_loader = get_dataloader(valset)\n",
    "test_temporal_loader = get_dataloader(testset)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "arima_model = ARIMA()\n",
    "arima_trainer = MlTrainer(arima_model)\n",
    "arima_trainer.train(train_temporal_loader)\n",
    "arima_trainer.evaluate(val_dataloader=val_temporal_loader)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# y_train = torch.squeeze(train_label).to(torch.int)\n",
    "y_train = torch.squeeze(preprocess.train_label)\n",
    "y_train = torch.mean(y_train,0).to(torch.int)\n",
    "print(y_train.shape)\n",
    "N = y_train[0] * 10000\n",
    "I0 = y_train[0]\n",
    "R0 = I0\n",
    "S0 = N - I0 - R0\n",
    "# print(S0, I0, R0)\n",
    "\n",
    "sir_model = SIR(S0=S0, I0= I0, R0=R0)\n",
    "sir_trainer = MlTrainer(sir_model)\n",
    "sir_trainer.train(train_dataloader = train_temporal_loader)\n",
    "sir_trainer.evaluate(val_dataloader= val_temporal_loader)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "trainset, valset, testset = preprocess.getMlDataSet()\n",
    "train_temporal_loader = get_dataloader(trainset)\n",
    "val_temporal_loader = get_dataloader(valset)\n",
    "test_temporal_loader = get_dataloader(testset)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "xgb = XGBoost()\n",
    "xgb_trainer = MlTrainer(xgb)\n",
    "xgb_trainer.train(train_dataloader=train_temporal_loader)\n",
    "xgb_trainer.evaluate(val_dataloader=val_temporal_loader)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original load way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "num_positions = dynamic_data.shape[0]\n",
    "spatio_indexes = []\n",
    "for i in range(3):\n",
    "    spatio_indexes.append(list(range(0,num_positions)))\n",
    "train_dynamic_data, train_static_data, train_label,val_dynamic_data, val_static_data, val_label, test_dynamic_data, test_static_data, test_label = split_by_spatio_temporal(dynamic_data= dynamic_data, static_data=static_data,label=label,temporal_rate=[0.6,0.2,0.2], spatio_indexes=spatio_indexes)\n",
    "train_dynamic_data.shape, train_static_data.shape, train_label.shape, val_dynamic_data.shape, val_static_data.shape, val_label.shape, test_dynamic_data.shape, test_static_data.shape, test_label.shape\n",
    "train_tps = TemporalDataPreprocess(train_dynamic_data, train_static_data, train_label, mode = 0, method = 'sum')\n",
    "val_tps = TemporalDataPreprocess(val_dynamic_data, val_static_data, val_label, mode = 0, method = 'sum')\n",
    "test_tps = TemporalDataPreprocess(test_dynamic_data, test_static_data, test_label, mode = 0, method = 'sum')\n",
    "train_data = train_tps.getMlData()\n",
    "train_label = train_tps.getMlLabel()\n",
    "val_data = val_tps.getMlData()\n",
    "val_label = val_tps.getMlLabel()\n",
    "train_data.shape, train_label.shape, val_data.shape, val_label.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "model = ARIMA()\n",
    "model.train(train_data, train_label)\n",
    "model.validate(val_data, val_label)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "y_train = torch.squeeze(train_label).to(torch.int)\n",
    "N = y_train[0] * 10000\n",
    "I0 = y_train[0]\n",
    "R0 = I0\n",
    "S0 = N - I0 - R0\n",
    "print(S0, I0, R0)\n",
    "\n",
    "y_val = torch.squeeze(val_label).to(torch.int)\n",
    "\n",
    "model = SIR(S0=S0, I0= I0, R0=R0)\n",
    "model.train(train_data, y_train)\n",
    "model.validate(val_data, y_val)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "y_train = torch.squeeze(train_label).to(torch.int)\n",
    "y_val = torch.squeeze(val_label).to(torch.int)\n",
    "N = y_train[0] * 10000\n",
    "I0 = y_train[0]\n",
    "R0 = I0\n",
    "E0 = I0 * 10\n",
    "S0 = N - I0 - R0 - E0\n",
    "print(S0, I0, R0)\n",
    "model = SEIR(S0,E0,I0,R0)\n",
    "model.train(train_data, y_train)\n",
    "model.validate(val_data, y_val)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "model = XGBoost()\n",
    "model.train(train_data, train_label)\n",
    "model.validate(val_data, val_label)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyEpi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
